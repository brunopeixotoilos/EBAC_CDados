{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBAC - Regressão II - regressão múltipla\n",
    "\n",
    "## Tarefa I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Previsão de renda II\n",
    "\n",
    "Vamos continuar trabalhando com a base 'previsao_de_renda.csv', que é a base do seu próximo projeto. Vamos usar os recursos que vimos até aqui nesta base.\n",
    "\n",
    "|variavel|descrição|\n",
    "|-|-|\n",
    "|data_ref                | Data de referência de coleta das variáveis |\n",
    "|index                   | Código de identificação do cliente|\n",
    "|sexo                    | Sexo do cliente|\n",
    "|posse_de_veiculo        | Indica se o cliente possui veículo|\n",
    "|posse_de_imovel         | Indica se o cliente possui imóvel|\n",
    "|qtd_filhos              | Quantidade de filhos do cliente|\n",
    "|tipo_renda              | Tipo de renda do cliente|\n",
    "|educacao                | Grau de instrução do cliente|\n",
    "|estado_civil            | Estado civil do cliente|\n",
    "|tipo_residencia         | Tipo de residência do cliente (própria, alugada etc)|\n",
    "|idade                   | Idade do cliente|\n",
    "|tempo_emprego           | Tempo no emprego atual|\n",
    "|qt_pessoas_residencia   | Quantidade de pessoas que moram na residência|\n",
    "|renda                   | Renda em reais|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('previsao_de_renda.csv')\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "df = pd.get_dummies(df, columns=['sexo', 'tipo_renda', 'educacao', 'estado_civil', 'tipo_residencia'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12427 entries, 0 to 14999\n",
      "Data columns (total 28 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Unnamed: 0                     12427 non-null  int64  \n",
      " 1   data_ref                       12427 non-null  object \n",
      " 2   id_cliente                     12427 non-null  int64  \n",
      " 3   posse_de_veiculo               12427 non-null  bool   \n",
      " 4   posse_de_imovel                12427 non-null  bool   \n",
      " 5   qtd_filhos                     12427 non-null  int64  \n",
      " 6   idade                          12427 non-null  int64  \n",
      " 7   tempo_emprego                  12427 non-null  float64\n",
      " 8   qt_pessoas_residencia          12427 non-null  float64\n",
      " 9   renda                          12427 non-null  float64\n",
      " 10  sexo_M                         12427 non-null  uint8  \n",
      " 11  tipo_renda_Bolsista            12427 non-null  uint8  \n",
      " 12  tipo_renda_Empresário          12427 non-null  uint8  \n",
      " 13  tipo_renda_Pensionista         12427 non-null  uint8  \n",
      " 14  tipo_renda_Servidor público    12427 non-null  uint8  \n",
      " 15  educacao_Pós graduação         12427 non-null  uint8  \n",
      " 16  educacao_Secundário            12427 non-null  uint8  \n",
      " 17  educacao_Superior completo     12427 non-null  uint8  \n",
      " 18  educacao_Superior incompleto   12427 non-null  uint8  \n",
      " 19  estado_civil_Separado          12427 non-null  uint8  \n",
      " 20  estado_civil_Solteiro          12427 non-null  uint8  \n",
      " 21  estado_civil_União             12427 non-null  uint8  \n",
      " 22  estado_civil_Viúvo             12427 non-null  uint8  \n",
      " 23  tipo_residencia_Casa           12427 non-null  uint8  \n",
      " 24  tipo_residencia_Com os pais    12427 non-null  uint8  \n",
      " 25  tipo_residencia_Comunitário    12427 non-null  uint8  \n",
      " 26  tipo_residencia_Estúdio        12427 non-null  uint8  \n",
      " 27  tipo_residencia_Governamental  12427 non-null  uint8  \n",
      "dtypes: bool(2), float64(3), int64(4), object(1), uint8(18)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Separe a base em treinamento e teste (25% para teste, 75% para treinamento).\n",
    "2. Rode uma regularização *ridge* com alpha = [0, 0.001, 0.005, 0.01, 0.05, 0.1] e avalie o $R^2$ na base de testes. Qual o melhor modelo?\n",
    "3. Faça o mesmo que no passo 2, com uma regressão *LASSO*. Qual método chega a um melhor resultado?\n",
    "4. Rode um modelo *stepwise*. Avalie o $R^2$ na vase de testes. Qual o melhor resultado?\n",
    "5. Compare os parâmetros e avalie eventuais diferenças. Qual modelo você acha o melhor de todos?\n",
    "6. Partindo dos modelos que você ajustou, tente melhorar o $R^2$ na base de testes. Use a criatividade, veja se consegue inserir alguma transformação ou combinação de variáveis.\n",
    "7. Ajuste uma árvore de regressão e veja se consegue um $R^2$ melhor com ela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from seaborn import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12427 entries, 0 to 14999\n",
      "Data columns (total 25 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   posse_de_veiculo               12427 non-null  bool   \n",
      " 1   posse_de_imovel                12427 non-null  bool   \n",
      " 2   qtd_filhos                     12427 non-null  int64  \n",
      " 3   idade                          12427 non-null  int64  \n",
      " 4   tempo_emprego                  12427 non-null  float64\n",
      " 5   qt_pessoas_residencia          12427 non-null  float64\n",
      " 6   renda                          12427 non-null  float64\n",
      " 7   sexo_M                         12427 non-null  uint8  \n",
      " 8   tipo_renda_Bolsista            12427 non-null  uint8  \n",
      " 9   tipo_renda_Empresário          12427 non-null  uint8  \n",
      " 10  tipo_renda_Pensionista         12427 non-null  uint8  \n",
      " 11  tipo_renda_Servidor público    12427 non-null  uint8  \n",
      " 12  educacao_Pós graduação         12427 non-null  uint8  \n",
      " 13  educacao_Secundário            12427 non-null  uint8  \n",
      " 14  educacao_Superior completo     12427 non-null  uint8  \n",
      " 15  educacao_Superior incompleto   12427 non-null  uint8  \n",
      " 16  estado_civil_Separado          12427 non-null  uint8  \n",
      " 17  estado_civil_Solteiro          12427 non-null  uint8  \n",
      " 18  estado_civil_União             12427 non-null  uint8  \n",
      " 19  estado_civil_Viúvo             12427 non-null  uint8  \n",
      " 20  tipo_residencia_Casa           12427 non-null  uint8  \n",
      " 21  tipo_residencia_Com os pais    12427 non-null  uint8  \n",
      " 22  tipo_residencia_Comunitário    12427 non-null  uint8  \n",
      " 23  tipo_residencia_Estúdio        12427 non-null  uint8  \n",
      " 24  tipo_residencia_Governamental  12427 non-null  uint8  \n",
      "dtypes: bool(2), float64(3), int64(2), uint8(18)\n",
      "memory usage: 825.2 KB\n"
     ]
    }
   ],
   "source": [
    "df_2 = df.drop(columns=['Unnamed: 0', 'data_ref', 'id_cliente'])\n",
    "\n",
    "df_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_2.drop(columns=['renda'])\n",
    "y = df_2['renda']\n",
    "\n",
    "# Dividir a base em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0, R²: 0.29796640176910294\n",
      "Alpha: 0.001, R²: 0.29796646662207804\n",
      "Alpha: 0.005, R²: 0.2979667258970613\n",
      "Alpha: 0.01, R²: 0.2979670496832443\n",
      "Alpha: 0.05, R²: 0.2979696277710634\n",
      "Alpha: 0.1, R²: 0.29797282035425066\n",
      "\n",
      "Melhor modelo: Alpha = 0.1, R² = 0.29797282035425066\n"
     ]
    }
   ],
   "source": [
    "# Lista de valores alpha\n",
    "alphas = [0, 0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "# Dicionário para armazenar os resultados de R²\n",
    "r2_ridge = {}\n",
    "\n",
    "# Ajustar modelos Ridge para diferentes valores de alpha\n",
    "for alpha in alphas:\n",
    "    ridge = Ridge(alpha=alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_ridge[alpha] = r2\n",
    "    print(f'Alpha: {alpha}, R²: {r2}')\n",
    "\n",
    "# Encontrar o melhor modelo com base no R²\n",
    "melhor_alpha = max(r2_ridge, key=r2_ridge.get)\n",
    "melhor_r2 = r2_ridge[melhor_alpha]\n",
    "\n",
    "print(f'\\nMelhor modelo: Alpha = {melhor_alpha}, R² = {melhor_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BrunodaCunhaPeixoto\\AppData\\Local\\Temp\\ipykernel_11136\\583919730.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  lasso.fit(X_train, y_train)\n",
      "C:\\Users\\BrunodaCunhaPeixoto\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\BrunodaCunhaPeixoto\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.036e+11, tolerance: 8.060e+07 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0, R²: 0.2979664017691016\n",
      "Alpha: 0.001, R²: 0.2979668708425244\n",
      "Alpha: 0.005, R²: 0.29796874449258226\n",
      "Alpha: 0.01, R²: 0.2979710806056549\n",
      "Alpha: 0.05, R²: 0.2979895317988459\n",
      "Alpha: 0.1, R²: 0.29801200134535355\n",
      "\n",
      "Melhor modelo: Alpha = 0.1, R² = 0.29801200134535355\n"
     ]
    }
   ],
   "source": [
    "# Dicionário para armazenar os resultados de R²\n",
    "r2_lasso = {}\n",
    "\n",
    "# Ajustar modelos Lasso para diferentes valores de alpha\n",
    "for alpha in alphas:\n",
    "    lasso = Lasso(alpha=alpha,  max_iter=10000)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    y_pred = lasso.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_lasso[alpha] = r2\n",
    "    print(f'Alpha: {alpha}, R²: {r2}')\n",
    "\n",
    "# Encontrar o melhor modelo com base no R²\n",
    "melhor_alpha = max(r2_lasso, key=r2_lasso.get)\n",
    "melhor_r2 = r2_lasso[melhor_alpha]\n",
    "\n",
    "print(f'\\nMelhor modelo: Alpha = {melhor_alpha}, R² = {melhor_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor modelo stepwise R²: 0.1595425826564727\n",
      "Características selecionadas: Index(['tempo_emprego'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Padronizar os dados (opcional, mas recomendado)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Ajustar um modelo de regressão linear inicial\n",
    "model = LinearRegression()\n",
    "\n",
    "# Usar RFE para seleção de características\n",
    "rfe = RFE(model, n_features_to_select=1)\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Selecionar as melhores características\n",
    "selected_features = rfe.support_\n",
    "\n",
    "# Ajustar o modelo com as melhores características\n",
    "model.fit(X_train_scaled[:, selected_features], y_train)\n",
    "\n",
    "# Avaliar o modelo no conjunto de teste\n",
    "y_pred = model.predict(X_test_scaled[:, selected_features])\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Melhor modelo stepwise R²: {r2}')\n",
    "\n",
    "# Obter os nomes das características selecionadas\n",
    "selected_feature_names = X.columns[selected_features]\n",
    "print(f'Características selecionadas: {selected_feature_names}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentre as 3 opções, o método que apresentou o melhor $R^2$ foi o Lasso. Para esse caso específico, o Lasso parece ser o modelo mais indicado, porém obteve resultado bastante parecido com Ridge. O Stepwise, por sua vez, apresentou um $R^2$ bem menor do que as outras alternativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeCV R²: 0.36709532516468846\n",
      "LassoCV R²: 0.3677380764325311\n",
      "Polynomial Features R²: -1.1832134016615758e+21\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# Criação de novas variáveis\n",
    "df['log_tempo_emprego'] = np.log1p(df['tempo_emprego'])\n",
    "\n",
    "# Transformar a variável dependente para o log da renda\n",
    "df['log_renda'] = np.log1p(df['renda'])\n",
    "\n",
    "# Separar as variáveis independentes (X) e dependentes (y)\n",
    "X = df.drop(columns=['Unnamed: 0', 'data_ref', 'id_cliente', 'renda', 'log_renda'])\n",
    "y = df['log_renda']\n",
    "\n",
    "# Dividir a base em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Padronizar os dados - Sem essa padronização, estava dando valores de R2 muito negativos.\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Regularização Ridge e Lasso com validação cruzada\n",
    "alphas = [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=5).fit(X_train_scaled, y_train)\n",
    "lasso_cv = LassoCV(alphas=alphas, cv=5).fit(X_train_scaled, y_train)\n",
    "\n",
    "ridge_cv_r2 = r2_score(y_test, ridge_cv.predict(X_test_scaled))\n",
    "lasso_cv_r2 = r2_score(y_test, lasso_cv.predict(X_test_scaled))\n",
    "\n",
    "print(f'RidgeCV R²: {ridge_cv_r2}')\n",
    "print(f'LassoCV R²: {lasso_cv_r2}')\n",
    "\n",
    "# Transformações polinomiais\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "X_test_poly = poly.transform(X_test_scaled)\n",
    "\n",
    "# Ajuste do modelo com transformações polinomiais\n",
    "model_poly = LinearRegression().fit(X_train_poly, y_train)\n",
    "poly_r2 = r2_score(y_test, model_poly.predict(X_test_poly))\n",
    "\n",
    "print(f'Polynomial Features R²: {poly_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com as transformações realizadas (log da renda e log do tempo emprego), obtivemos um valor de $R^2$ maior que os vistos anteriormente, sendo o valor do Lasso ligeiramente maior que o Ridge. Na hora de transformar em um polinômio, no entanto, o valor do $R^2$ ficou bastante descalibrado, com um valor muito grande e negativo, o que indica um possível overfitting do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Regression Train R²: 0.7793849578261296\n",
      "Tree Regression Test R²: 0.29137664738855806\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# Ajustar a árvore de regressão\n",
    "X = df.drop(columns=['Unnamed: 0', 'data_ref', 'id_cliente', 'renda', 'log_renda'])\n",
    "y = df['log_renda']\n",
    "\n",
    "tree_regressor = DecisionTreeRegressor(random_state=42)\n",
    "tree_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Previsões e cálculo do R²\n",
    "y_train_pred = tree_regressor.predict(X_train_scaled)\n",
    "y_test_pred = tree_regressor.predict(X_test_scaled)\n",
    "\n",
    "tree_train_r2 = r2_score(y_train, y_train_pred)\n",
    "tree_test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Tree Regression Train R²: {tree_train_r2}')\n",
    "print(f'Tree Regression Test R²: {tree_test_r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na base de treinamento, a árvore atingiu um $R^2$ bastante elevado, de quase 80%. No teste, no entanto, o valor caiu para 29%, abaixo dos valores obtidos com Ridge e Lasso após as transformações."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
